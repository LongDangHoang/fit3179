{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "all_df = pd.read_csv('./data/Production_Crops_Livestock_E_All_Data/Production_Crops_Livestock_E_All_Data_NOFLAG.csv', encoding=\"ISO-8859-1\", keep_default_na=False, dtype={'Item Code': str})\n",
    "lat_lon_code = pd.read_csv('./data/world_country_and_usa_states_latitude_and_longitude_values.csv', keep_default_na=False)\n",
    "\n",
    "lat_lon_code = pd.read_csv('./data/world_country_and_usa_states_latitude_and_longitude_values.csv')\n",
    "lat_lon_code = lat_lon_code.sort_values(by=['Country']).drop_duplicates(subset=['Alpha-2 code'])\n",
    "lat_lon_code.loc[:, \"Numeric code\"] = lat_lon_code[\"Numeric code\"].str.strip(' \"').astype(int)\n",
    "lat_lon_code.loc[:, \"Alpha-2 code\"] = lat_lon_code[\"Alpha-2 code\"].str.strip(' \"')\n",
    "lat_lon_code.loc[:, \"Alpha-3 code\"] = lat_lon_code[\"Alpha-3 code\"].str.strip(' \"')\n",
    "lat_lon_code.loc[:, \"Latitude (average)\"] = lat_lon_code[\"Latitude (average)\"].str.strip(' \"').astype(float)\n",
    "lat_lon_code.loc[:, \"Longitude (average)\"] = lat_lon_code[\"Longitude (average)\"].str.strip(' \"').astype(float)\n",
    "area_code_to_iso_dict = lat_lon_code[[\"Numeric code\", \"Alpha-2 code\"]].set_index(\"Numeric code\")['Alpha-2 code'].to_dict()\n",
    "\n",
    "all_df.loc[:, 'Area Code (M49)'] = all_df['Area Code (M49)'].str.strip(\" '\").astype(int)\n",
    "all_df.loc[:, 'ISO-A2'] = all_df['Area Code (M49)'].replace(area_code_to_iso_dict)\n",
    "all_df = all_df[all_df['ISO-A2'].isin(lat_lon_code['Alpha-2 code'])]\n",
    "\n",
    "def make_year_cols(start, end):\n",
    "    return [f'Y{y}' for y in range(start, end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df.merge(\n",
    "    lat_lon_code[['Latitude (average)', 'Longitude (average)', 'Country', 'Alpha-2 code', 'Alpha-3 code']],\n",
    "    how='left',\n",
    "    left_on='ISO-A2',\n",
    "    right_on='Alpha-2 code',\n",
    ")\n",
    "\n",
    "all_df = all_df.melt(\n",
    "    id_vars=[\"Country\", \"ISO-A2\", \"Alpha-3 code\", \"Longitude (average)\", \"Latitude (average)\", 'Item', 'Item Code', 'Element', 'Unit'], \n",
    "    value_vars=make_year_cols(2000, 2021), \n",
    "    value_name='Quantity', \n",
    "    var_name='Year'\n",
    ")\n",
    "\n",
    "all_df['Year'] = all_df['Year'].str.strip('Y').astype(int)\n",
    "all_df['Quantity'] = all_df['Quantity'].replace({'': 0})\n",
    "all_df['Quantity'] = all_df['Quantity'].astype(float)\n",
    "all_df = all_df.rename(columns={\"Country\": \"Area\"})\n",
    "all_df.loc[:, 'Area'] = all_df['Area'].apply(lambda x: x if not x.endswith('of') and not x.endswith('of the') else ' '.join(x.split(', ')[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('./data/population_by_country.csv')\n",
    "population = population.melt(\n",
    "    id_vars=['Country Name', 'Country Code'],\n",
    "    value_vars=[str(y) for y in range(2000, 2021)],\n",
    "    value_name='Population',\n",
    "    var_name='Year',\n",
    ")\n",
    "\n",
    "population['Year'] = population['Year'].astype(int)\n",
    "all_df = pd.merge(\n",
    "    all_df, population,\n",
    "    how='left',\n",
    "    left_on=['Alpha-3 code', 'Year'],\n",
    "    right_on=['Country Code', 'Year']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent = pd.read_csv('./data/UNSD — Methodology.csv', sep=';', encoding='utf-8', keep_default_na=False)\n",
    "all_df = all_df.merge(\n",
    "    continent[['Region Name', 'ISO-alpha2 Code']],\n",
    "    how='left',\n",
    "    left_on='ISO-A2',\n",
    "    right_on='ISO-alpha2 Code'\n",
    ").rename(columns={'Region Name': 'Continent'}).drop(columns=['ISO-alpha2 Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('./data/cpc_codes.csv', encoding='ISO-8859-1', dtype={'CPC21code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_type_lookup = {\n",
    "    '011': 'Cereals',\n",
    "    '012': 'Vegetables',\n",
    "    '013': 'Fruits and nuts',\n",
    "    '211': 'Meat and meat products',\n",
    "    '22': 'Dairy and egg'\n",
    "}\n",
    "\n",
    "manual_code_to_item = {\n",
    "    '211': ['Meat of camels, fresh or chilled', 'Meat of cattle with the bone, fresh or chilled', 'Meat of pig with the bone, fresh or chilled', 'Meat of asses, fresh or chilled', 'Meat of mules, fresh or chilled', 'Meat of other domestic camelids, fresh or chilled', 'Meat of other domestic rodents, fresh or chilled', 'Meat of pigeons and other birds n.e.c., fresh, chilled or frozen'] + ['Edible offal of cattle, fresh, chilled or frozen', 'Edible offal of goat, fresh, chilled or frozen', 'Edible offal of sheep, fresh, chilled or frozen', 'Edible offal of pigs, fresh, chilled or frozen', 'Edible offal of buffalo, fresh, chilled or frozen'],\n",
    "    '22': ['Raw milk of camel', 'Raw milk of cattle', 'Raw milk of goats', 'Raw milk of sheep', 'Raw milk of buffalo', 'Hen eggs in shell, fresh', 'Eggs from other birds in shell, fresh, n.e.c.'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, code_type in code_to_type_lookup.items():\n",
    "    if code in manual_code_to_item:\n",
    "        all_df.loc[all_df['Item'].isin(manual_code_to_item[code]), 'Item Hierarchy Type'] = code_type\n",
    "    else:\n",
    "        all_item_types = codes[codes['CPC21code'].str.startswith(code)]['CPC21title']\n",
    "        all_df.loc[all_df['Item'].isin(all_item_types), 'Item Hierarchy Type'] = code_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yield', 'Production', 'Laying', 'Milk Animals'], dtype=object)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[all_df['Item Hierarchy Type'] == 'Dairy and egg']['Element'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ne_110m.json', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_name in all_df['Area'].unique():\n",
    "    if text.find('\"NAME\":\"{}\"'.format(country_name)) == -1:\n",
    "        print(country_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrangle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = [\n",
    "    'Area',\n",
    "    'ISO-A2',\n",
    "    \"Unit\",\n",
    "    'Latitude (average)',\n",
    "    'Longitude (average)',\n",
    "    'Continent',\n",
    "    'Year',\n",
    "    'Population',\n",
    "    'Item Hierarchy Type'\n",
    "]\n",
    "\n",
    "remove_if_null_in_subset = [\"ISO-A2\", \"Continent\", \"Quantity\", \"Item Hierarchy Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_df[\n",
    "    (all_df['Element'] == 'Production') &\\\n",
    "    (all_df['Unit'] == 'tonnes')\n",
    "].copy()\n",
    "df.loc[:, 'Quantity'] = df['Quantity'].fillna(0) # so sum groupby keeps\n",
    "df = df.groupby([\n",
    "    'Area',\n",
    "    'ISO-A2',\n",
    "    'Item Hierarchy Type',\n",
    "    'Latitude (average)',\n",
    "    'Longitude (average)',\n",
    "    'Continent',\n",
    "    'Population',\n",
    "    'Year',\n",
    "    'Element',\n",
    "    'Unit',\n",
    "])['Quantity'].sum().reset_index().dropna(\n",
    "  axis=0,\n",
    "  how='any',\n",
    "  subset=remove_if_null_in_subset\n",
    ")[[\n",
    "    'Area',\n",
    "    'ISO-A2',\n",
    "    'Item Hierarchy Type',\n",
    "    'Latitude (average)',\n",
    "    'Longitude (average)',\n",
    "    'Continent',\n",
    "    'Population',\n",
    "    'Year',\n",
    "    'Quantity'\n",
    "]]\n",
    "\n",
    "df.to_csv('data/processed/production_major_categories_per_country_2000-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_elements = ['Area harvested', 'Producing Animals/Slaughtered', 'Milk Animals', 'Laying']\n",
    "df = all_df[all_df['Element'].isin(production_elements + ['Production'])]\n",
    "df = df.dropna(subset=remove_if_null_in_subset, how='any')\n",
    "\n",
    "count_producing_unit = df[df['Element'].isin(production_elements)].copy()\n",
    "count_producing_unit['Quantity'] = count_producing_unit['Quantity'].fillna(0) # aggregate by sum so set to 0\n",
    "count_producing_unit = count_producing_unit.groupby(['ISO-A2', 'Year', 'Element', 'Unit', 'Item Hierarchy Type'])['Quantity'].sum().reset_index()\n",
    "count_producing_unit['Quantity no multiplier'] = count_producing_unit['Quantity'] * 999 * count_producing_unit['Unit'].str.startswith('1000') + count_producing_unit['Quantity']\n",
    "count_producing_unit['Unit no multiplier'] = count_producing_unit['Unit'].str.replace('1000 ', '')\n",
    "assert count_producing_unit.notna().all(axis=0).all()\n",
    "\n",
    "total_producing_unit = count_producing_unit.groupby(['ISO-A2', 'Year', 'Unit no multiplier', 'Item Hierarchy Type'])['Quantity no multiplier'].sum().reset_index()\n",
    "total_prod = df[(df['Element'] == 'Production') & (df['Unit'] == 'tonnes')].groupby(['ISO-A2', 'Year', 'Item Hierarchy Type'])['Quantity'].sum().reset_index()\n",
    "total_producing_unit.rename(columns={\"Quantity no multiplier\": \"Producing unit quantity\", \"Unit no multiplier\": \"Producing unit\"}, inplace=True)\n",
    "total_prod.rename(columns={\"Quantity\": \"Production quantity\"}, inplace=True)\n",
    "\n",
    "merged = pd.merge(\n",
    "    total_producing_unit, total_prod,\n",
    "    on=['ISO-A2', 'Year', 'Item Hierarchy Type']\n",
    ")\n",
    "merged['Quantity'] = merged['Production quantity'] / merged['Producing unit quantity']\n",
    "merged = merged.drop(columns=['Producing unit quantity', 'Production quantity', 'Producing unit'])\n",
    "merged = merged.merge(\n",
    "    df[['ISO-A2', 'Area', 'Year', 'Continent', 'Population', 'Latitude (average)', 'Longitude (average)']].drop_duplicates(), \n",
    "    how='left',\n",
    "    on=['ISO-A2', 'Year']\n",
    ")\n",
    "merged = merged.dropna(subset=remove_if_null_in_subset, how='any')\n",
    "merged.to_csv('./data/processed/yield_major_categories_per_country_2000-2020.csv', index=False)\n",
    "\n",
    "total_producing_unit_globe = total_producing_unit.groupby(['Year', 'Item Hierarchy Type'])['Producing unit quantity'].sum().reset_index()\n",
    "total_prod_glob = total_prod.groupby(['Year', 'Item Hierarchy Type'])['Production quantity'].sum().reset_index()\n",
    "\n",
    "average_yield = pd.merge(\n",
    "    total_producing_unit_globe, total_prod_glob,\n",
    "    on=['Year', 'Item Hierarchy Type']\n",
    ")\n",
    "\n",
    "def year_on_year(df: pd.DataFrame):\n",
    "    df = df.set_index('Year').sort_index().copy()\n",
    "    df['Quantity'] = df['Production quantity'] / df['Producing unit quantity']\n",
    "    return (df['Quantity'] - df['Quantity'].shift(1))\n",
    "\n",
    "growth = average_yield.groupby(['Item Hierarchy Type']).apply(year_on_year).reset_index().drop(columns=[2000]).melt(id_vars=['Item Hierarchy Type']).rename(columns={\"value\": \"yield growth\"})\n",
    "average_yield = average_yield.merge(\n",
    "    growth,\n",
    "    how='left',\n",
    "    on=['Year', 'Item Hierarchy Type']\n",
    ")\n",
    "average_yield.to_csv('./data/processed/production_yield_global_2000_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Item Hierarchy Type</th>\n",
       "      <th>Producing unit quantity</th>\n",
       "      <th>Production quantity</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>Cereals</td>\n",
       "      <td>6.655916e+08</td>\n",
       "      <td>2.046690e+09</td>\n",
       "      <td>3.074993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>Dairy and egg</td>\n",
       "      <td>5.704988e+09</td>\n",
       "      <td>6.329329e+08</td>\n",
       "      <td>0.110944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>Fruits and nuts</td>\n",
       "      <td>5.031708e+07</td>\n",
       "      <td>4.417205e+08</td>\n",
       "      <td>8.778740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>Meat and meat products</td>\n",
       "      <td>3.676797e+09</td>\n",
       "      <td>1.607517e+08</td>\n",
       "      <td>0.043721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>2.848049e+07</td>\n",
       "      <td>7.781348e+08</td>\n",
       "      <td>27.321675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Cereals</td>\n",
       "      <td>7.218593e+08</td>\n",
       "      <td>2.980950e+09</td>\n",
       "      <td>4.129545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Dairy and egg</td>\n",
       "      <td>8.586382e+09</td>\n",
       "      <td>9.741701e+08</td>\n",
       "      <td>0.113455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Fruits and nuts</td>\n",
       "      <td>6.615674e+07</td>\n",
       "      <td>7.088890e+08</td>\n",
       "      <td>10.715295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>Meat and meat products</td>\n",
       "      <td>4.814223e+09</td>\n",
       "      <td>1.954239e+08</td>\n",
       "      <td>0.040593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year     Item Hierarchy Type  Producing unit quantity  \\\n",
       "0       NaN                     NaN                      NaN   \n",
       "1    2000.0                 Cereals             6.655916e+08   \n",
       "2    2000.0           Dairy and egg             5.704988e+09   \n",
       "3    2000.0         Fruits and nuts             5.031708e+07   \n",
       "4    2000.0  Meat and meat products             3.676797e+09   \n",
       "..      ...                     ...                      ...   \n",
       "100  2019.0              Vegetables             2.848049e+07   \n",
       "101  2020.0                 Cereals             7.218593e+08   \n",
       "102  2020.0           Dairy and egg             8.586382e+09   \n",
       "103  2020.0         Fruits and nuts             6.615674e+07   \n",
       "104  2020.0  Meat and meat products             4.814223e+09   \n",
       "\n",
       "     Production quantity   Quantity  \n",
       "0                    NaN        NaN  \n",
       "1           2.046690e+09   3.074993  \n",
       "2           6.329329e+08   0.110944  \n",
       "3           4.417205e+08   8.778740  \n",
       "4           1.607517e+08   0.043721  \n",
       "..                   ...        ...  \n",
       "100         7.781348e+08  27.321675  \n",
       "101         2.980950e+09   4.129545  \n",
       "102         9.741701e+08   0.113455  \n",
       "103         7.088890e+08  10.715295  \n",
       "104         1.954239e+08   0.040593  \n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_yield.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Item Hierarchy Type   \n",
       "2000  Cereals                   6.655916e+08\n",
       "      Dairy and egg             5.704988e+09\n",
       "      Fruits and nuts           5.031708e+07\n",
       "      Meat and meat products    3.676797e+09\n",
       "      Vegetables                2.313421e+07\n",
       "                                    ...     \n",
       "2020  Cereals                   7.218593e+08\n",
       "      Dairy and egg             8.586382e+09\n",
       "      Fruits and nuts           6.615674e+07\n",
       "      Meat and meat products    4.814223e+09\n",
       "      Vegetables                2.873227e+07\n",
       "Name: Quantity, Length: 105, dtype: float64"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_producing_unit_globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_df[\n",
    "    (all_df[\"Element\"] == \"Production\") &\\\n",
    "    (all_df[\"Unit\"] == 'tonnes') &\\\n",
    "    # (all_df[\"Year\"] == '2020')\n",
    "].dropna(\n",
    "  axis=0,\n",
    "  how='any',\n",
    "  subset=remove_if_null_in_subset,\n",
    ").groupby([\"Item\", \"Item Hierarchy Type\", \"Year\"])[[\"Quantity\"]]\\\n",
    " .sum()\\\n",
    " .reset_index()\n",
    "\n",
    "df.to_csv('./data/processed/production_all_category_2020.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83ba8c25ac7bdcad8fa6ab945f509c99c516dc83a4d0f1a4152a0c57e3660ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
